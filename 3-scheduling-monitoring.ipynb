{
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "notebookId": "42mbrrrw54lbxr6rz3o7",
      "authorId": "1693111827356",
      "authorName": "USER",
      "authorEmail": "",
      "sessionId": "1af49dab-2500-49f6-a50c-0af4eac56313",
      "lastEditTime": 1747353714002
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a32acc9a-10cd-4ab6-874c-4ababd3c91c3",
      "metadata": {
        "name": "cell1",
        "collapsed": false
      },
      "source": "# Part 3: Bringing Workflows to Production\n\n## Scheduling Python Jobs\n\nIn Snowflake, [Tasks](https://docs.snowflake.com/en/user-guide/tasks-intro) are used to automate and schedule jobs. Tasks can schedule the execution of a Notebook, a stored procedure, or arbitrary SQL statements. In this Notebook, you will learn how to use a Task to schedule a Python Stored Procedure to apply the Customer Loyalty Score UDAF on a schedule. Next, you will learn how to set up telemetry collection for the job and set up alerts.\n\n## Creating a Python Stored Procedure\n\nIf you're not already familiar with [Stored Procedures](https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview), they allow you to run *procedural* code, like loops, if/else blocks, and other patterns which are hard to do in SQL alone. \n\nTo create a Python Stored Procedure, all we need is a Python function that accepts a Snowpark Session object as its first argument. In Snowflake we call this the \"handler\" for the procedure. For example, the Python function below is a bare-bones procedure handler that uses the Session object which returns an integer:\n\n```python\nfrom snowflake.snowpark import Session\n\ndef my_handler(sess: Session) -> int:\n    n_rows = sess.table('my_table').count()\n    return n_rows\n```\n\nLet's create a procedure to calculate the Customer Loyalty scores and write them to an output table. Then, we will schedule it with a Task so we can have up-to-date loyalty scores. "
    },
    {
      "cell_type": "markdown",
      "id": "1a2601b6-8e5f-495a-88be-7a09d0858883",
      "metadata": {
        "name": "cell2",
        "collapsed": false
      },
      "source": "In the package picker, add the package `snowflake.core`. This package is the [Python API for Snowflake](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/reference/latest/index)."
    },
    {
      "cell_type": "code",
      "id": "85c1943f-1386-4094-a3b8-81b5431cc746",
      "metadata": {
        "language": "python",
        "name": "cell3",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "from snowflake.snowpark import Session\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit\nimport logging\n\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "2cf1c890-23b0-422d-9f46-ed6d4de0ee0b",
      "metadata": {
        "language": "python",
        "name": "cell4"
      },
      "outputs": [],
      "source": "from snowflake.snowpark.types import IntegerType\n\n# Handler for the procedure\ndef calc_loyalty_scores(sess: Session) -> int:\n    logging.info('Starting loyalty score procedure')\n    calculated_at = datetime.now()\n    \n    sess.sql(\"\"\"\n        SELECT\n          CUSTOMER_ID,\n          LoyaltyScoreUDAF(ORDER_TOTAL, ORDER_TS) AS loyalty_score\n        FROM tasty_bytes_orders\n        WHERE \n            ORDER_TOTAL IS NOT NULL \n            AND ORDER_TS IS NOT NULL\n            AND CUSTOMER_ID IS NOT NULL\n        GROUP BY CUSTOMER_ID\n        ORDER BY loyalty_score DESC\n    \"\"\").with_column(\"calculated_at\", lit(calculated_at))\\\n    .write\\\n    .save_as_table('loyalty_scores', mode='append')\n\n    # Returns the number of rows in the output table\n    return sess.table('tasty_bytes_orders').count()\n\n\n# Register the handler as a Stored Procedure\nloyalty_sproc = session.sproc.register(\n    calc_loyalty_scores,\n    return_type=IntegerType(),\n    name='calculate_loyalty_scores',\n    is_permanent=True,\n    packages=['snowflake-telemetry-python'],\n    stage_location='@my_stage/',\n    replace=True\n)\n\nprint(f'Created procedure \"{loyalty_sproc.name}\"')",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "00b0acbd-7065-4754-93e7-d669818fc079",
      "metadata": {
        "language": "sql",
        "name": "cell5",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "-- Call the stored proc for a test run\nCALL CALCULATE_LOYALTY_SCORES();",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "24b8201c-f131-4fe6-9954-43382fb9a5ee",
      "metadata": {
        "name": "cell6",
        "collapsed": false
      },
      "source": "If you click **Monitoring** > **Query History** from the table of contents on the left you should be able to see the `CALL CALCULATE_LOYALTY_SCORES();` query in the list. (Tip: you can hold Ctrl as you click **Query History** to open it in a new tab.)"
    },
    {
      "cell_type": "markdown",
      "id": "90f938b9-3d17-47fe-b846-a364815fb12a",
      "metadata": {
        "name": "cell7",
        "collapsed": false
      },
      "source": "Now let's create a Task to run this stored procedure on a schedule. Check out the docs on [`CREATE TASK`](https://docs.snowflake.com/en/sql-reference/sql/create-task) for more information, but at its core a Task needs a **schedule** and a **warehouse**. For example, the SQL below defines a Task that runs every hour with the Warehouse, `my_wh`, and calls a stored procedure named `my_stored_procedure`.\n\n```sql\nUSE DATABASE TEST_DB;\nUSE SCHEMA TEST_SCHEMA;\n\nCREATE TASK my_task\n  WAREHOUSE = my_wh\n  SCHEDULE = '60 MINUTES'\n  AS\n    CALL my_stored_procedure\n```\n\nAnd of course, you can define the same Task using Python!\n\n```python\nfrom datetime import timedelta\nfrom snowflake.core.task import Cron, Task\n\ntasks = root.databases[\"TEST_DB\"].schemas[\"TEST_SCHEMA\"].tasks\n\ntask = tasks.create(\n    Task(\n        name=\"my_task\",\n        definition=\"CALL my_stored_procedure\",\n        schedule=Cron(\"0 * * * *\", \"America/Los_Angeles\"),\n        warehouse=\"my_wh\"\n    ),\n)\n```"
    },
    {
      "cell_type": "code",
      "id": "1c93436e-79a0-4f0f-88c4-13e1cb09ceaf",
      "metadata": {
        "language": "python",
        "name": "cell8"
      },
      "outputs": [],
      "source": "# Let's create a Task in Python\nfrom snowflake.core import Root\nfrom snowflake.core.task import Cron, Task\n\nroot = Root(session)\ntasks = root.databases[\"HOL_DB\"].schemas[\"PUBLIC\"].tasks\nschedule = Cron(\"*/5 * * * *\", \"America/Los_Angeles\")  # every 5 minutes\n\ntask = tasks.create(\n    Task(\n        name=\"loyalty_score\",\n        definition=\"CALL HOL_DB.PUBLIC.CALCULATE_LOYALTY_SCORES();\",\n        schedule=schedule,\n        warehouse=\"my_wh\"\n    ),\n    mode=\"orreplace\"\n)\n\n# Start the task, will run every 5 minutes now\ntask.resume()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1ac7e2fd-0a09-46f7-8b18-2554fae3fad5",
      "metadata": {
        "name": "cell9",
        "collapsed": false
      },
      "source": "Now the Task, `loyalty_score`, should be running every 5 minutes. In the Database browser on the left, find your database and under the PUBLIC schema you should see the `loyalty_score` Task listed under the *Tasks* tab.\n\n![Task Location](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/navigate_to_task.png) \n\nClick the task and it will bring you to the page for the Task. Click the **Run History** page to see the executions of the Task.\n\nRemember, the task is running every 5th minute, so you may not see an execution in the history tab right away. You can call [`task.execute()`](https://docs.snowflake.com/en/developer-guide/snowflake-python-api/reference/latest/_autosummary/snowflake.core.task.TaskResource#snowflake.core.task.TaskResource) to force an execution of the task independent of its schedule."
    },
    {
      "cell_type": "code",
      "id": "5e5ac7a1-84b3-4086-9fb6-84cffdf7576a",
      "metadata": {
        "language": "python",
        "name": "cell10",
        "codeCollapsed": false
      },
      "outputs": [],
      "source": "# Now let's stop the Task's execution\ntask.suspend()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "da1ad170-89b1-44e7-8a39-c6473725960a",
      "metadata": {
        "name": "cell11",
        "collapsed": false
      },
      "source": "## Monitoring Python Workloads\n\nNow we have a simple Python job scheduled to execute every 5 minutes. This raises the question: how do we monitor this job as it's running? How can we be notified if it fails overnight? How can we track performance over time? Snowflake provides a [suite of observability capabilities](https://www.snowflake.com/en/product/features/snowflake-trail/) to help you address those questions. Let's go over a few of Snowflake's observability capabilities:\n\n1. Telemetry Collection: You can route any [logs](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging), [metrics](https://docs.snowflake.com/en/developer-guide/logging-tracing/metrics), or [traces](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing) from your jobs to Snowflake's Event Tables for storage and alerting.\n1. History tables: Use the [Query History](https://docs.snowflake.com/en/user-guide/ui-snowsight-activity), [Copy History](https://docs.snowflake.com/en/user-guide/data-load-monitor), and [Task History](https://docs.snowflake.com/en/user-guide/ui-snowsight-tasks) to monitor all usage in your account.\n1. [Alerts and Notifications](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-alerts-notifications): Alerts allow for customizable triggering conditions, actions, and a schedule, in combination with notification integrations for proactive monitoring.\n1. [Extensibility with third-party tools](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-tools-analysis-visualization): The Snowflake [event table](https://docs.snowflake.com/en/developer-guide/logging-tracing/event-table-setting-up) adopts [OpenTelemetry](https://opentelemetry.io/docs/) standards, so your Snowflake telemetry can easily be consumed by other ecosystem tools."
    },
    {
      "cell_type": "markdown",
      "id": "1c0d995d-a2ce-41cd-a6fa-5de1c33126d5",
      "metadata": {
        "name": "cell12",
        "collapsed": false
      },
      "source": "## Event Table Setup\n\nThe Event Table is the central storage system for logs, metrics, and traces in your account. A [default Event Table](https://docs.snowflake.com/developer-guide/logging-tracing/event-table-setting-up#use-the-default-event-table) is already created at `snowflake.telemetry.events`. Let's enable it:"
    },
    {
      "cell_type": "code",
      "id": "20d9b603-5d00-4e5c-bce6-0e654b3686c2",
      "metadata": {
        "language": "sql",
        "name": "cell13"
      },
      "outputs": [],
      "source": "ALTER ACCOUNT SET EVENT_TABLE = snowflake.telemetry.events;",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "119bb4e8-ac78-4ac7-9fff-d79905b97891",
      "metadata": {
        "name": "cell14",
        "collapsed": false
      },
      "source": "Next, we'll enable the collection of logs, metrics, and traces in our account."
    },
    {
      "cell_type": "code",
      "id": "32bff270-e3e6-494e-a695-bd0a33068035",
      "metadata": {
        "language": "sql",
        "name": "cell15"
      },
      "outputs": [],
      "source": "ALTER ACCOUNT SET LOG_LEVEL = 'INFO';\nALTER ACCOUNT SET METRIC_LEVEL = 'ALL';\nALTER ACCOUNT SET TRACE_LEVEL = 'ALWAYS';",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "7af20828-fe80-48cd-90fc-a79f433d72b7",
      "metadata": {
        "name": "cell16",
        "collapsed": false
      },
      "source": "We're now collecting logs, metrics, and traces for all jobs in our account. To test this, let's run our Task again. "
    },
    {
      "cell_type": "code",
      "id": "dba2072d-0f25-48f7-8dcd-d6d48cbf9df0",
      "metadata": {
        "language": "python",
        "name": "cell17"
      },
      "outputs": [],
      "source": "task.execute()",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "17d5a7af-ab08-491d-8732-9bcf1ef6023f",
      "metadata": {
        "name": "cell18",
        "collapsed": false
      },
      "source": "After running this procedure, go to **Monitoring** > **Traces and Logs** > **Log Explorer**. You should see the log message \"`Starting loyalty score procedure`\" from the procedure in the **Log Explorer**. You can use the filters at the top to find the log message. Look under the Object column for the name of the procedure, \"`CALCULATE_LOYALTY_SCORES()`\". (Tip: you can open the **Monitoring** page in a new browser tab by holding Ctrl as you click the tab.)\n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/log_explorer.png)\n\nClick that log line and a pane will open on the right with more information about the log entry, like the object which emitted it, the warehouse used, and the file and line where the log line was emitted from. \n\nClick the button to go the Query associated with the log.\n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/link_to_query_page.png)\n"
    },
    {
      "cell_type": "markdown",
      "id": "f91b0409-9b94-4bb2-b33d-fe342a57cc95",
      "metadata": {
        "name": "cell19",
        "collapsed": false
      },
      "source": "In the page for the Query, the \"Query Telemetry\" tab will show the trace diagram for the job. In this page, each row is a **span** representing a unit of work. In this case, there are spans for the Stored Procedure execution, the DataFrame queries, and the UDAF. \n\n![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/trace_diagram.png)\n\nThe concept of [spans and traces](https://opentelemetry.io/docs/concepts/observability-primer/#distributed-traces) come from [OpenTelemetry](https://opentelemetry.io/), a project in the Cloud Native Compute Foundation. OpenTelemetry is often used in observability for application infrastructure, and Snowflake has applied it to native primitives such as Stored Procedures, UDFs, DataFrames, and soon to Queries, Tasks, Notebooks, Snowpark Container Services, and more!"
    },
    {
      "cell_type": "markdown",
      "id": "e5eca549-d161-4984-b4ec-68b33fd63907",
      "metadata": {
        "name": "cell20",
        "collapsed": false
      },
      "source": "## Custom Telemetry\n\n### Logs\n\nSnowflake will collect any logs emitted by your Python code, even logs from packages you're calling. If you want to add more logs to your jobs so you can monitor and debug better in the future, you can just run `import logging` and add logging statements like `logging.warn(\"This is a warning message\")`. [More information](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-python#stored-procedure-example).\n\n### Span Events\n\nYou can also add custom spans using [`telemetry.set_span_attribute()`](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-python#adding-span-attributes), these are similar to logs but they can be more useful for attaching structured data like lists and dictionaries. This data will show in the \"Span Events\" tab of the Trace Diagram.\n\n### Custom Spans\n\nWant more granularity in your tracing? You can also add [custom spans](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-custom-spans) in your jobs, this can be helpful to segment off parts of your code so you can see how long those particular pieces take to run ([Python example](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing-custom-spans#python-example))."
    },
    {
      "cell_type": "markdown",
      "id": "efd52eea-eaac-4c13-9585-2c1ac797f3e1",
      "metadata": {
        "name": "cell21",
        "collapsed": false
      },
      "source": "## Exercise\n\nTake some time to try adding additional logs, custom spans, or span events to the Stored Procedure above and executing the Task. Then browse to the Query Telemetry tab and see what's available!"
    },
    {
      "cell_type": "markdown",
      "id": "689e57c5-56d8-4817-9b51-63a65becdf4c",
      "metadata": {
        "name": "cell22",
        "collapsed": false
      },
      "source": "## Next Steps\n\nCongratulations! Over these three Notebooks you've learned how to query data with Snowpark pandas, write user defined functions, external access, schedule jobs with Tasks, and monitor your jobs with logs, metrics, and traces. Now that you've completed this Hands-on Lab, here are some additional resources to keep learning.\n\n### Create email notifications \n\nTry using what you learned about logs, metrics, and traces to create an alert if a job throws an error log or if a Task fails. This is a great way to stay on top of your scheduled data pipelines. To do so, use Snowflake's [alerts](http://docs.snowflake.com/en/user-guide/alerts) feature.\n\n- [`SYSTEM$SEND_EMAIL()`](https://docs.snowflake.com/en/sql-reference/stored-procedures/system_send_email)\n- [Send email notifications](https://docs.snowflake.com/en/user-guide/notifications/email-notifications)\n\n### Visualize Data in Streamlit\n\nIf you're new to Python, you can keep learning by creating data visualizations and data-powered applications with Streamlit in Snowflake! This is a great way to learn more Python and incorporate it into your day-to-day workflows as a data professional.\n\n- [Get Started with Snowpark and Streamlit](https://quickstarts.snowflake.com/guide/getting_started_with_snowpark_for_python_streamlit/#0)\n- [Getting Started with Stramlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/getting-started)\n- [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)\n\n"
    }
  ]
}