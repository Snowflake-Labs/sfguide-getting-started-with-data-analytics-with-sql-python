{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a32acc9a-10cd-4ab6-874c-4ababd3c91c3",
      "metadata": {
        "collapsed": false,
        "name": "cell1"
      },
      "source": [
        "# Part 3: Bringing Workflows to Production\n",
        "\n",
        "For the purpose of this demo, let's add the `snowflake` package.\n",
        "\n",
        "## Scheduling Python Jobs\n",
        "\n",
        "In Snowflake, [Tasks](https://docs.snowflake.com/en/user-guide/tasks-intro) are used to automate and schedule jobs. Tasks can schedule the execution of a Notebook, a stored procedure, or arbitrary SQL statements. In this Notebook, you will learn how to use a Task to schedule a Python Stored Procedure to apply the Customer Loyalty Score UDAF on a schedule. Next, you will learn how to set up telemetry collection for the job and set up alerts.\n",
        "\n",
        "## Creating a Python Stored Procedure\n",
        "\n",
        "If you're not already familiar with [Stored Procedures](https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-overview), they allow you to run *procedural* code, like loops, if/else blocks, and other patterns which are hard to do in SQL alone. \n",
        "\n",
        "To create a Python Stored Procedure, all we need is a Python function that accepts a Snowpark Session object as its first argument. In Snowflake we call this the \"handler\" for the procedure. For example, the Python function below is a bare-bones procedure handler that uses the Session object which returns an integer:\n",
        "\n",
        "```python\n",
        "from snowflake.snowpark import Session\n",
        "\n",
        "def my_handler(sess: Session) -> int:\n",
        "    n_rows = sess.table('my_table').count()\n",
        "    return n_rows\n",
        "```\n",
        "\n",
        "Let's create a procedure to calculate the Customer Loyalty scores and write them to an output table. Then, we will schedule it with a Task so we can have up-to-date loyalty scores. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c1943f-1386-4094-a3b8-81b5431cc746",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell2"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark import Session\n",
        "from datetime import datetime\n",
        "from snowflake.snowpark.functions import lit\n",
        "import logging\n",
        "\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf1c890-23b0-422d-9f46-ed6d4de0ee0b",
      "metadata": {
        "language": "python",
        "name": "cell3"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.types import IntegerType\n",
        "\n",
        "# Handler for the procedure\n",
        "def calc_loyalty_scores(sess: Session) -> int:\n",
        "    logging.info('Starting loyalty score procedure')\n",
        "    calculated_at = datetime.now()\n",
        "    \n",
        "    sess.sql(\"\"\"\n",
        "        SELECT\n",
        "          CUSTOMER_ID,\n",
        "          LoyaltyScoreUDAF(ORDER_TOTAL, ORDER_TS) AS loyalty_score\n",
        "        FROM tasty_bytes_orders\n",
        "        WHERE \n",
        "            ORDER_TOTAL IS NOT NULL \n",
        "            AND ORDER_TS IS NOT NULL\n",
        "            AND CUSTOMER_ID IS NOT NULL\n",
        "        GROUP BY CUSTOMER_ID\n",
        "        ORDER BY loyalty_score DESC\n",
        "    \"\"\").with_column(\"calculated_at\", lit(calculated_at))\\\n",
        "    .write\\\n",
        "    .save_as_table('loyalty_scores', mode='append')\n",
        "\n",
        "    # Returns the number of rows in the output table\n",
        "    return sess.table('tasty_bytes_orders').count()\n",
        "\n",
        "\n",
        "# Register the handler as a Stored Procedure\n",
        "loyalty_sproc = session.sproc.register(\n",
        "    calc_loyalty_scores,\n",
        "    return_type=IntegerType(),\n",
        "    name='calculate_loyalty_scores',\n",
        "    is_permanent=True,\n",
        "    stage_location='@my_stage/',\n",
        "    replace=True\n",
        ")\n",
        "\n",
        "print(f'Created procedure \"{loyalty_sproc.name}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b0acbd-7065-4754-93e7-d669818fc079",
      "metadata": {
        "codeCollapsed": false,
        "language": "sql",
        "name": "cell4"
      },
      "outputs": [],
      "source": [
        "-- Call the stored proc for a test run\n",
        "CALL CALCULATE_LOYALTY_SCORES();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90f938b9-3d17-47fe-b846-a364815fb12a",
      "metadata": {
        "collapsed": false,
        "name": "cell5"
      },
      "source": [
        "Now let's create a Task to run this stored procedure on a schedule. Check out the docs for [`CREATE TASK`](https://docs.snowflake.com/en/sql-reference/sql/create-task) for more information, but at its core a Task needs a **schedule** and a **warehouse**. For example, the SQL below defines a Task that runs every hour with the Warehouse, `my_wh`, and calls a stored procedure named `my_stored_procedure`.\n",
        "\n",
        "```sql\n",
        "USE DATABASE TEST_DB;\n",
        "USE SCHEMA TEST_SCHEMA;\n",
        "\n",
        "CREATE TASK my_task\n",
        "  WAREHOUSE = my_wh\n",
        "  SCHEDULE = '60 MINUTES'\n",
        "  AS\n",
        "    CALL my_stored_procedure\n",
        "```\n",
        "\n",
        "And of course, you can define the same Task using Python!\n",
        "\n",
        "```python\n",
        "from datetime import timedelta\n",
        "from snowflake.core.task import Cron, Task\n",
        "\n",
        "tasks = root.databases[\"TEST_DB\"].schemas[\"TEST_SCHEMA\"].tasks\n",
        "\n",
        "task = tasks.create(\n",
        "    Task(\n",
        "        name=\"my_task\",\n",
        "        definition=\"CALL my_stored_procedure\",\n",
        "        schedule=Cron(\"0 * * * *\", \"America/Los_Angeles\"),\n",
        "        warehouse=\"my_wh\"\n",
        "    ),\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c93436e-79a0-4f0f-88c4-13e1cb09ceaf",
      "metadata": {
        "language": "python",
        "name": "cell6"
      },
      "outputs": [],
      "source": [
        "# Let's create a Task in Python\n",
        "from snowflake.core import Root\n",
        "from snowflake.core.task import Cron, Task\n",
        "\n",
        "root = Root(session)\n",
        "tasks = root.databases[\"HOL_DB\"].schemas[\"PUBLIC\"].tasks\n",
        "schedule = Cron(\"*/5 * * * *\", \"America/Los_Angeles\")  # every 5 minutes\n",
        "\n",
        "task = tasks.create(\n",
        "    Task(\n",
        "        name=\"loyalty_score\",\n",
        "        definition=\"CALL HOL_DB.PUBLIC.CALCULATE_LOYALTY_SCORES();\",\n",
        "        schedule=schedule,\n",
        "        warehouse=\"my_wh\"\n",
        "    ),\n",
        "    mode=\"orreplace\"\n",
        ")\n",
        "\n",
        "# Start the task, will run every 5 minutes now\n",
        "task.resume()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac7e2fd-0a09-46f7-8b18-2554fae3fad5",
      "metadata": {
        "collapsed": false,
        "name": "cell7"
      },
      "source": [
        "Now the Task, `loyalty_score`, should be running every 5 minutes. In the Database browser on the left, find your database and under the PUBLIC schema you should see the `loyalty_score` Task listed under the *Tasks* tab.\n",
        "\n",
        "![Task Location](https://github.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/blob/main/images/task_location.png?raw=True) \n",
        "\n",
        "Click the task and it will bring you to the page for the Task. Click the **Run History** page to see the executions of the Task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5ac7a1-84b3-4086-9fb6-84cffdf7576a",
      "metadata": {
        "language": "python",
        "name": "cell8"
      },
      "outputs": [],
      "source": [
        "# Now let's stop the Task's execution\n",
        "task.suspend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1ad170-89b1-44e7-8a39-c6473725960a",
      "metadata": {
        "collapsed": false,
        "name": "cell9"
      },
      "source": [
        "## Monitoring Python Workloads\n",
        "\n",
        "Now we have a simple Python job scheduled to execute every 5 minutes. This raises the question: how do we monitor this job as it's running? How can we be notified if it fails overnight? How can we track performance over time? Snowflake provides a [suite of observability capabilities](https://www.snowflake.com/en/product/features/snowflake-trail/) to help you address those questions. Let's go over a few of Snowflake's observability capabilities:\n",
        "\n",
        "1. Telemetry Collection: You can route any [logs](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging), [metrics](https://docs.snowflake.com/en/developer-guide/logging-tracing/metrics), or [traces](https://docs.snowflake.com/en/developer-guide/logging-tracing/tracing) from your jobs to Snowflake's Event Tables for storage and alerting.\n",
        "1. History tables: Use the [Query History](https://docs.snowflake.com/en/user-guide/ui-snowsight-activity), [Copy History](https://docs.snowflake.com/en/user-guide/data-load-monitor), and [Task History](https://docs.snowflake.com/en/user-guide/ui-snowsight-tasks) to monitor all usage in your account.\n",
        "1. [Alerts and Notifications](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-alerts-notifications): Alerts allow for customizable triggering conditions, actions, and a schedule, in combination with notification integrations for proactive monitoring.\n",
        "1. [Extensibility with third-party tools](https://docs.snowflake.com/en/developer-guide/builders/observability#label-observability-tools-analysis-visualization): The Snowflake [event table](https://docs.snowflake.com/en/developer-guide/logging-tracing/event-table-setting-up) adopts [OpenTelemetry](https://opentelemetry.io/docs/) standards, so your Snowflake telemetry can easily be consumed by other ecosystem tools."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c0d995d-a2ce-41cd-a6fa-5de1c33126d5",
      "metadata": {
        "collapsed": false,
        "name": "cell10"
      },
      "source": [
        "## Event Table Setup\n",
        "\n",
        "The Event Table is the central storage system for logs, metrics, and traces in your account. A [default Event Table](https://docs.snowflake.com/developer-guide/logging-tracing/event-table-setting-up#use-the-default-event-table) is already created at `snowflake.telemetry.events`. Let's enable it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d9b603-5d00-4e5c-bce6-0e654b3686c2",
      "metadata": {
        "language": "sql",
        "name": "cell11"
      },
      "outputs": [],
      "source": [
        "ALTER ACCOUNT SET EVENT_TABLE = snowflake.telemetry.events;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119bb4e8-ac78-4ac7-9fff-d79905b97891",
      "metadata": {
        "collapsed": false,
        "name": "cell12"
      },
      "source": [
        "Next, we'll enable the collection of logs, metrics, and traces in our account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32bff270-e3e6-494e-a695-bd0a33068035",
      "metadata": {
        "language": "sql",
        "name": "cell13"
      },
      "outputs": [],
      "source": [
        "ALTER ACCOUNT SET LOG_LEVEL = 'INFO';\n",
        "ALTER ACCOUNT SET METRIC_LEVEL = 'ALL';\n",
        "ALTER ACCOUNT SET TRACE_LEVEL = 'ALWAYS';"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af20828-fe80-48cd-90fc-a79f433d72b7",
      "metadata": {
        "collapsed": false,
        "name": "cell14"
      },
      "source": [
        "We're now collecting logs, metrics, and traces for all jobs in our account. To test this, let's run our stored procedure in the cell below. After running this procedure, go to **Monitoring** > **Traces and Logs** > **Log Explorer**. You should see the log message \"`Starting loyalty score procedure`\" from the procedure in the **Log Explorer**. You can use the filters at the top to find the log message. Look under the Object column for the name of the procedure, \"`CALCULATE_LOYALTY_SCORES()`\".\n",
        "\n",
        "![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/log_explorer.png?token=GHSAT0AAAAAADCOV42CEFCF5UPR5AYAGZQ22AFO46A)\n",
        "\n",
        "Click that log line and a pane will open on the right with more information about the log entry, like the object which emitted it, the warehouse used, and the file and line where the log line was emitted from. \n",
        "\n",
        "Click the button to go the Query associated with the log.\n",
        "\n",
        "![](https://raw.githubusercontent.com/Snowflake-Labs/sfguide-getting-started-with-data-analytics-with-sql-python/refs/heads/main/images/link_to_query_page.png?token=GHSAT0AAAAAADCOV42DHY4VTYASB2E6LYZU2AFPABQ)\n",
        "\n",
        "TODO:\n",
        "1. Show trace diagram\n",
        "1. select span, show metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5eca549-d161-4984-b4ec-68b33fd63907",
      "metadata": {
        "collapsed": false,
        "name": "cell15"
      },
      "source": [
        "## Custom Telemetry\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "689e57c5-56d8-4817-9b51-63a65becdf4c",
      "metadata": {
        "collapsed": false,
        "name": "cell16"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Congratulations! Over these three Notebooks you've learned how to query data with Snowpark pandas, write user defined functions, external access, schedule jobs with Tasks, and monitor your jobs with logs, metrics, and traces. Now that you've completed this Hands-on Lab, here are some additional resources to keep learning.\n",
        "\n",
        "### Create email notifications \n",
        "\n",
        "Try using what you learned about logs, metrics, and traces to create an alert if a job throws an error log or if a Task fails. This is a great way to stay on top of your scheduled data pipelines. To do so, use Snowflake's [alerts](http://docs.snowflake.com/en/user-guide/alerts) feature.\n",
        "\n",
        "- [`SYSTEM$SEND_EMAIL()`](https://docs.snowflake.com/en/sql-reference/stored-procedures/system_send_email)\n",
        "- [Send email notifications](https://docs.snowflake.com/en/user-guide/notifications/email-notifications)\n",
        "\n",
        "### Visualize Data in Streamlit\n",
        "\n",
        "If you're new to Python, you can keep learning by creating data visualizations and data-powered applications with Streamlit in Snowflake! This is a great way to learn more Python and incorporate it into your day-to-day workflows as a data professional.\n",
        "\n",
        "- [Get Started with Snowpark and Streamlit](https://quickstarts.snowflake.com/guide/getting_started_with_snowpark_for_python_streamlit/#0)\n",
        "- [Getting Started with Stramlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/getting-started)\n",
        "- [Streamlit in Snowflake](https://docs.snowflake.com/en/developer-guide/streamlit/about-streamlit)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Streamlit Notebook",
      "name": "streamlit"
    },
    "lastEditStatus": {
      "authorEmail": "",
      "authorId": "9077286868697",
      "authorName": "USER",
      "lastEditTime": 1747255781074,
      "notebookId": "2nkv4a77jilxhim237nr",
      "sessionId": "2d8f3f2e-0a59-4ec8-9c4f-62c297e98955"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
