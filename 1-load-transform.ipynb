{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "7zzkiqmlqvhkphldgvfd",
   "authorId": "56160401252",
   "authorName": "DOLEE",
   "authorEmail": "doris.lee@snowflake.com",
   "sessionId": "29fd7ea4-20e2-4199-9226-563ff9181568",
   "lastEditTime": 1744753342529
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087ecc02-bbc7-488d-beae-796574cfed71",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "# Snowflake Summit 2025 DE107 - Orchestrating Data Analytics Workloads with SQL and Python"
  },
  {
   "cell_type": "markdown",
   "id": "a2023d59-d73a-442a-ac73-99ab145bf1b1",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "### Learning Objective:\n\n- Ease of bringing data into Snowflake\n  - Participants will learn how to read files (CSV, Parquet, Excel) using Python and extracting information from those files \n- The power of Python UDFs and common use cases for them\n  - Participants will learn about when they should use a UDF, UDTF, UDAF, and Stored Procedure for building their data pipeline\n  - Participants will learn about external access and how to make a basic web request in a Python UDF\n- The benefits of writing queries in Python and the basics of (pandas) DataFrames\n  - Participants will learn about the modularity and composability of DataFrames: a DataFrame can be imported to multiple files, shared across projects, and tested individually. \n  - Participants will learn that iterative and programmatic specification of data transformation is easier in Python than SQL\n  - Participants will learn that handling complex datatypes is easier in Python (like working with JSON)\n- How to monitor and troubleshoot Python jobs in Snowflake\n  - Participants will be introduced to Event Tables and what traces are\n  - Participants will learn how to create a basic email notification based on their error logs\n- (Optional, if participants finish early): How to schedule a Python stored procedure with Tasks\n  - Participants will learn how to schedule their Notebook/SP (#3) with a Task\n- (Optional) The extent of the PyData ecosystem and how to incorporate it into their jobs\n  - Participants will be introduced to a popular analytics Python package (data viz?) and generating reports using that data\n"
  },
  {
   "cell_type": "markdown",
   "id": "e0a89459-6d2e-4a33-8f7f-0ba3127468a2",
   "metadata": {
    "name": "cell33",
    "collapsed": false
   },
   "source": "## Adding Python Packages ðŸŽ’\n\nSnowflake Notebooks comes pre-installed with common Python libraries for data science ðŸ§ª and machine learning ðŸ§ , such as numpy, pandas, matplotlib, streamlit and more!\n\nIf you are looking to use other packages, click on the `Packages` dropdown on the top right to add additional packages to your notebook.\n\nFor the purpose of this demo, let's add the following packages: \n- `modin` (version `0.30.1`)\n- `openpyxl`\n- `s3fs`\n- `snowflake-ml-python`"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "import streamlit as st\nimport modin.pandas as pd\nimport snowflake.snowpark.modin.plugin",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0374405-b02f-4ddf-95e3-2b281c54480e",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "## Connecting to Snowflake \n\nTo work with your data in Snowflake, you need to first get a session variable to connect to Snowflake. Since you are already logged in to Snowflake Notebook, you can get your session variable directly through the active notebook session. The session variable is the entrypoint that gives you access to using Snowflake's Python API, including Snowpark."
  },
  {
   "cell_type": "code",
   "id": "3e55fa97-d8ac-49a2-8e0b-4c4e40a635b0",
   "metadata": {
    "language": "python",
    "name": "cell34",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd6e3bba-c22d-4fd4-81a0-a75fc60e98e3",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Bringing data into Snowflake\nYou can use pandas on Snowflake to load in [CSV](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/modin/pandas_api/modin.pandas.read_csv#modin.pandas.read_csv), [Parquet](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/modin/pandas_api/modin.pandas.read_parquet#modin.pandas.read_parquet), and [Excel](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/modin/pandas_api/modin.pandas.read_excel#modin.pandas.read_excel) from stage or local file location. Here is the full list of [I/O functionalities supported](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/1.30.0/modin/io).\n"
  },
  {
   "cell_type": "markdown",
   "id": "7d840837-0238-4aa2-ba98-4343ac8ef4a2",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "First let's create a external stage and upload the CSV file. "
  },
  {
   "cell_type": "code",
   "id": "1973fc8a-c443-4b0f-a5fe-6aa3933511d9",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Create a external stage (Note: this is not required if running outside of notebook due to EAI)\nCREATE OR REPLACE STAGE FROSTBYTES\n    URL = 's3://sfquickstarts/frostbyte_tastybytes/';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bab997af-990b-4747-af20-a5477e79597a",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item = pd.read_csv(\"@frostbytes/analytics/menu_item_aggregate_v.csv\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3e574dc-bc9a-49d5-b585-535563692d38",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "menu_item.head()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb6d40c5-2a63-4465-a337-680258ca9819",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "## Profiling and summary statistics\nWe can look at the size and overall descriptive statistics of our dataframe `menu_item`.  "
  },
  {
   "cell_type": "code",
   "id": "b7aa66fa-54e6-4df6-8dd4-86a72e54c0a5",
   "metadata": {
    "language": "python",
    "name": "cell22",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item.shape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7c75ba0-12b7-4512-a5ca-18cf4b66293e",
   "metadata": {
    "language": "python",
    "name": "cell30",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "menu_item.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7162683-eecf-46c6-ade2-a7dc1db2172a",
   "metadata": {
    "language": "python",
    "name": "cell38",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import altair as alt\nnumeric_cols = ['PRICE', 'BASE_PRICE', 'COST_OF_GOODS_USD', 'COUNT_ORDERS', 'TOTAL_QUANTITY_SOLD']\ncols = st.columns(len(numeric_cols))\nfor idx, col in enumerate(numeric_cols):\n    with cols[idx]:\n        chart = alt.Chart(menu_item).mark_bar().encode(\n            alt.X(f'{col}:Q', bin=True, title=col),\n            alt.Y('count():Q', title='Count'),\n            tooltip=['count()']\n        ).properties(\n            width=200,  \n            height=300,\n            title=f'Distribution of {col}'\n        ).configure_title(\n            fontSize=14 \n        )\n        st.altair_chart(chart, use_container_width=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2f33c330-431b-40d1-978b-d93d00670653",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "## Data Cleaning and Transformation\n\nNow let's clean up the data by performnign some filtering and aggregation.\n"
  },
  {
   "cell_type": "code",
   "id": "9c946c47-1bc0-4103-9f9a-7dd23e21a2b9",
   "metadata": {
    "language": "python",
    "name": "cell29",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Filter to only records in January 2023\nmenu_item[\"DATE\"] = pd.to_datetime(menu_item[\"DATE\"])\nfiltered_menu_item = menu_item[(menu_item[\"DATE\"]>'2023-01-01')&(menu_item[\"DATE\"]<'2023-02-01')]\nst.markdown(f'There are {len(menu_item)} rows in the full. After filtering, there are {len(filtered_menu_item)} rows in this daterange.' )",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "122e6f94-9a8f-49cf-b5fb-4ce84e20ded6",
   "metadata": {
    "language": "python",
    "name": "cell41",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[\"MENU_ITEM_NAME\"].value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "195a19ed-7d84-43c7-b13a-2e953401ef0d",
   "metadata": {
    "language": "python",
    "name": "cell32",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.markdown(f'''There are {len(filtered_menu_item[\"MENU_ITEM_NAME\"].unique())} different menu items. \\n\nThat's a lot of different items! Let's see how we can group them into fewer categories.''')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c0d8331-0735-4d23-9d81-e93b61378926",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "Next, to clean up the data further, we want to to classify menu items into a smaller number of categories. We can do that using Snowflake's Cortex LLM functions [CLASSIFY](https://docs.snowflake.com/en/sql-reference/functions/classify_text-snowflake-cortex). You can use Snowflake Cortex LLM functions via the Snowpark pandas apply function, see examples [here](https://docs.snowflake.com/en/developer-guide/snowpark/python/pandas-on-snowflake#using-snowflake-cortex-llm-functions-with-snowpark-pandas)."
  },
  {
   "cell_type": "code",
   "id": "887c2a61-bb27-484e-9749-afb3eed65678",
   "metadata": {
    "language": "python",
    "name": "cell27",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import ClassifyText\nfiltered_menu_item[\"MENU_ITEM_CATEGORY\"] = filtered_menu_item[\"MENU_ITEM_NAME\"].apply(ClassifyText, categories=[\"Meal\",\"Dessert\",\"Drinks\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfb43652-7ee8-4493-8e4d-3173f4000124",
   "metadata": {
    "language": "python",
    "name": "cell12",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[\"MENU_ITEM_CATEGORY\"]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3ec55ed-b988-4e7a-a609-54baa854b3e9",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "Now let's extract the `label` field from the dictionary in the column."
  },
  {
   "cell_type": "code",
   "id": "47857b2d-6444-48d3-b556-4ec91c00e043",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[\"MENU_ITEM_LABEL\"] = filtered_menu_item[\"MENU_ITEM_CATEGORY\"].apply(lambda x: x.get('label'))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "230dfa5c-0ba0-4416-a8ff-f736048a5621",
   "metadata": {
    "language": "python",
    "name": "cell39",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[\"MENU_ITEM_LABEL\"]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a18b52ff-7768-41d2-a6dc-ff1dff870d86",
   "metadata": {
    "name": "cell40",
    "collapsed": false
   },
   "source": "We can now count the occurrences of each unique value of `MENU_ITEM_LABEL` in the dataframe. We see that most of the records are meals and drinks, with a few desserts and unclassified rows."
  },
  {
   "cell_type": "code",
   "id": "07ece988-1054-4607-b7cd-b32145cd4bf7",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[\"MENU_ITEM_LABEL\"].value_counts()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5c9403f-93cc-4874-b47f-687fddb9f8b7",
   "metadata": {
    "name": "cell43"
   },
   "source": "I want to manually examine the records that are unclassified and see what they look like: "
  },
  {
   "cell_type": "code",
   "id": "5a7979fb-83cd-4a67-98ea-a76699dbc569",
   "metadata": {
    "language": "python",
    "name": "cell42",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "filtered_menu_item[filtered_menu_item[\"MENU_ITEM_LABEL\"]==\"UNCLASSIFIED\"]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a816c3bb-7d32-4837-8747-f88c9079b018",
   "metadata": {
    "name": "cell23",
    "collapsed": false
   },
   "source": "We are interested in looking specifically at the sales of Buffalo Mac & Cheese across different food trucks. "
  },
  {
   "cell_type": "code",
   "id": "da82a32c-cc56-4473-a01e-be9108c6b01e",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "buffalo_mac_cheese = menu_item[menu_item[\"MENU_ITEM_NAME\"]==\"Buffalo Mac & Cheese\"]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb46639d-66d1-4956-a91c-60c4749a9858",
   "metadata": {
    "name": "cell44"
   },
   "source": "Next, we perform a join to combine our `buffalo_mac_cheese` dataframe with another dataframe `order_item`."
  },
  {
   "cell_type": "code",
   "id": "86a9aff5-f9d2-4db1-8b22-68e7d3caa0d9",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "order_item = pd.read_csv(\"@frostbytes/analytics/order_item_cost_agg_v.csv\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "812b1685-ba83-4e89-9bcf-649a7c60e5f4",
   "metadata": {
    "language": "python",
    "name": "cell45",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "order_item",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eeff2987-d49a-44bc-bc7f-d17578fea1ef",
   "metadata": {
    "name": "cell46"
   },
   "source": "By looking at `order_item`, we see that it has separate month year columns, but `buffalo_mac_cheese` (from the original `menu_item`) has one combined `DATE`, so let's extract the year and month column."
  },
  {
   "cell_type": "code",
   "id": "ce63e2ad-3cb0-4c1a-b565-c6a98996ec08",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Extract year and month to conform with data in `order_item`\nbuffalo_mac_cheese['YEAR'] = buffalo_mac_cheese['DATE'].dt.year\nbuffalo_mac_cheese['MONTH'] = buffalo_mac_cheese['DATE'].dt.month",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a5224e9-a3ec-40e1-bdd8-13db45bcd52b",
   "metadata": {
    "name": "cell47",
    "collapsed": false
   },
   "source": "Now let's groupby the year month and menu type."
  },
  {
   "cell_type": "code",
   "id": "f38268f7-a838-4a00-b569-eff45ad6261a",
   "metadata": {
    "language": "python",
    "name": "cell28",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Group by YEAR and MONTH\ngrouped_bmc = buffalo_mac_cheese.groupby(['YEAR', 'MONTH','MENU_TYPE_ID'])[\"COUNT_ORDERS\",\"TOTAL_QUANTITY_SOLD\"].sum().reset_index()\ngrouped_bmc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b173a162-7f17-4783-8e87-fcf945425e1f",
   "metadata": {
    "name": "cell37"
   },
   "source": "Now that we have the same join key on the two tables, we can merge the columns together."
  },
  {
   "cell_type": "code",
   "id": "7c02d63a-e95f-4675-83ec-1a7946045731",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Now merge with order_item on YEAR and MONTH\nmerged_df = grouped_bmc.merge(order_item, on=['YEAR', 'MONTH'])\nmerged_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69999655-e385-4e59-9939-b97b7709e49d",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.markdown(\"This is how the dataframe size changed from performing the merge operation:\")\nst.markdown(f\"order_item size: {order_item.shape} + grouped_bmc size: {grouped_bmc.shape} -> merged_df size: {merged_df.shape}\")",
   "execution_count": null
  }
 ]
}